{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import itertools as it\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import tree_sitter_languages\n",
    "from tree_sitter import Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/jtl86/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/jtl86/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_JAVA_LANGUAGE = tree_sitter_languages.get_language(\"java\")\n",
    "_JAVA_PARSER = tree_sitter_languages.get_parser(\"java\")\n",
    "_JAVA_QUERY = _JAVA_LANGUAGE.query(\n",
    "    \"\"\"\n",
    "    (class_declaration\n",
    "        name: (identifier) @identifier) @class\n",
    "    (record_declaration\n",
    "        name: (identifier) @identifier) @record\n",
    "    (enum_declaration\n",
    "        name: (identifier) @identifier) @enum\n",
    "    (interface_declaration\n",
    "        name: (identifier) @identifier) @interface\n",
    "    (annotation_type_declaration\n",
    "        name: (identifier) @identifier) @annotation\n",
    "    (method_declaration\n",
    "        name: (identifier) @identifier) @method\n",
    "    (constructor_declaration\n",
    "        name: (identifier) @identifier) @constructor\n",
    "    (field_declaration\n",
    "        declarator: (variable_declarator\n",
    "            name: (identifier) @identifier)) @field\n",
    "    (line_comment) @line_comment\n",
    "    (block_comment) @block_comment\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TS_QUERY = \"\"\"\n",
    "#     (class_declaration\n",
    "#         name: (identifier) @identifier) @class\n",
    "#     (method_declaration\n",
    "#         name: (identifier) @identifier) @method\n",
    "#     (constructor_declaration\n",
    "#         name: (identifier) @identifier) @constructor\n",
    "#     (field_declaration\n",
    "#         declarator: (variable_declarator\n",
    "#             name: (identifier) @identifier)) @field\n",
    "#     (block_comment) @block_comment\n",
    "#     [(line_comment) (block_comment)] @comment\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _CaptureKind(enum.Enum):\n",
    "    \"\"\"Different capture kinds found in `JAVA_QUERY`.\"\"\"\n",
    "\n",
    "    # Types\n",
    "    ANNOTATION = 1\n",
    "    CLASS = 2\n",
    "    ENUM = 3\n",
    "    INTERFACE = 4\n",
    "    RECORD = 5\n",
    "\n",
    "    # Functions\n",
    "    CONSTRUCTOR = 6\n",
    "    METHOD = 7\n",
    "\n",
    "    # Fields\n",
    "    FIELD = 8\n",
    "\n",
    "    # Block comment (includes both normal block comments and doc comments)\n",
    "    LINE_COMMENT = 9\n",
    "    BLOCK_COMMENT = 10\n",
    "\n",
    "    # Identifier\n",
    "    IDENTIFIER = 11\n",
    "\n",
    "    def is_function(self) -> bool:\n",
    "        return self == _CaptureKind.CONSTRUCTOR or self == _CaptureKind.METHOD\n",
    "\n",
    "    def is_comment(self) -> bool:\n",
    "        return self == _CaptureKind.LINE_COMMENT or self == _CaptureKind.BLOCK_COMMENT\n",
    "\n",
    "    # def is_tag(self) -> bool:\n",
    "    #     \"\"\"A tag is a source code entity that could be part of the call graph.\"\"\"\n",
    "    #     return not (\n",
    "    #         self == _CaptureKind.BLOCK_COMMENT or self == _CaptureKind.IDENTIFIER\n",
    "    #     )\n",
    "\n",
    "    # def is_simple_tag(self) -> bool:\n",
    "    #     \"\"\"A simple tag is a tag that is not a type.\"\"\"\n",
    "    #     return (\n",
    "    #         self == _CaptureKind.CONSTRUCTOR\n",
    "    #         or self == _CaptureKind.METHOD\n",
    "    #         or self == _CaptureKind.FIELD\n",
    "    #     )\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class _Capture:\n",
    "    node: Node\n",
    "    kind: _CaptureKind\n",
    "\n",
    "\n",
    "def _determine_lineage(node_a: Node, node_b: Node) -> tuple[Node, Node] | None:\n",
    "    \"\"\"\n",
    "    Calculate the ancestor-descendant relationship between two nodes.\n",
    "\n",
    "    Returns the tuple (ancestor, descendant). If the two nodes do not have\n",
    "    a strict ancestor-descendant relationship, then None is returned.\n",
    "    \"\"\"\n",
    "    a0, a1 = node_a.byte_range\n",
    "    b0, b1 = node_b.byte_range\n",
    "    # Check if completely overlapping\n",
    "    if a0 == b0 and a1 == b1:\n",
    "        # TODO: Throw exception instead?\n",
    "        return None\n",
    "    # Check if there is no overlap\n",
    "    if a1 <= b0 or b1 <= a0:\n",
    "        return None\n",
    "    # Check if a completely surrounds b\n",
    "    if a0 <= b0 and b1 <= a1:\n",
    "        return node_a, node_b\n",
    "    # Check if b completely surrounds a\n",
    "    if b0 <= a0 and a1 <= b1:\n",
    "        return node_b, node_a\n",
    "    # There is some amount of overlap but no clear hierarchy\n",
    "    # TODO: Throw exception instead?\n",
    "    return None\n",
    "\n",
    "\n",
    "def _calculate_parents_dict(nodes: list[Node]) -> dict[Node, Node | None]:\n",
    "    \"\"\"Given a list of nodes, return a child-to-parent mapping.\"\"\"\n",
    "    parents: dict[Node, Node | None] = {n: None for n in nodes}\n",
    "    for node_a, node_b in it.combinations(nodes, 2):\n",
    "        if (lineage := _determine_lineage(node_a, node_b)) is None:\n",
    "            continue\n",
    "        ancestor, descendant = lineage\n",
    "        current_parent = parents.get(descendant, None)\n",
    "        if current_parent is None:\n",
    "            parents[descendant] = ancestor\n",
    "            continue\n",
    "        if (lineage := _determine_lineage(current_parent, ancestor)) is None:\n",
    "            raise RuntimeError(\n",
    "                \"Two nodes with a common descendent have a non-overlapping byte range\"\n",
    "            )\n",
    "        parents[descendant] = lineage[1]\n",
    "    return parents\n",
    "\n",
    "\n",
    "def _to_children_dict(\n",
    "    parents: dict[Node, Node | None],\n",
    ") -> dict[Node | None, list[Node]]:\n",
    "    \"\"\"Return a parent-to-children mapping given a child-to-parent mapping.\"\"\"\n",
    "    children: dict[Node | None, list[Node]] = defaultdict(list)\n",
    "    for child, parent in parents.items():\n",
    "        children[parent].append(child)\n",
    "    return dict(children)\n",
    "\n",
    "\n",
    "def _get_roots(children: dict[Node | None, list[Node]]) -> list[Node]:\n",
    "    return children.get(None, [])\n",
    "\n",
    "\n",
    "def _get_node_text(node: Node, content_bytes: bytes) -> str:\n",
    "    return content_bytes[node.start_byte : node.end_byte].decode()\n",
    "\n",
    "\n",
    "def _find_captures(content_bytes: bytes) -> dict[int, _Capture]:\n",
    "    captures: dict[int, _Capture] = {}\n",
    "    tree = _JAVA_PARSER.parse(content_bytes)\n",
    "    for node, capture_name in _JAVA_QUERY.captures(tree.root_node):\n",
    "        captures[node.id] = _Capture(node, _CaptureKind[capture_name.upper()])\n",
    "    return captures\n",
    "\n",
    "\n",
    "# def _find_class_members(captures: dict[int, _Capture]) -> list[Node] | None:\n",
    "#     \"\"\"Return the members of the top-level class in their original order.\n",
    "\n",
    "#     If a single top-level class does not exist, return None.\n",
    "#     \"\"\"\n",
    "#     nodes = [c.node for c in captures.values()]\n",
    "#     parents = _calculate_parents_dict(nodes)\n",
    "#     children = _to_children_dict(parents)\n",
    "#     roots = _get_roots(children)\n",
    "#     root_classes = [r for r in roots if captures[r.id].kind == _CaptureKind.CLASS]\n",
    "#     if len(root_classes) != 1:\n",
    "#         return None\n",
    "#     members = [m for m in children[root_classes[0]] if captures[m.id].kind]\n",
    "#     members.sort(key=lambda m: m.byte_range)\n",
    "#     return members\n",
    "\n",
    "\n",
    "# @dataclass\n",
    "# class ClassWithSimpleMembers:\n",
    "#     is_class: bool\n",
    "#     members: list[str]\n",
    "\n",
    "\n",
    "# def report_simple_class_members(content: str) -> ClassWithSimpleMembers:\n",
    "#     content_bytes = content.encode()\n",
    "#     captures = _find_captures(content_bytes)\n",
    "#     members = _find_class_members(captures)\n",
    "#     if members is None:\n",
    "#         return ClassWithSimpleMembers(False, [])\n",
    "#     simple_members: list[Node] = []\n",
    "#     for member in members:\n",
    "#         if captures[member.id].kind.is_simple_tag():\n",
    "#             simple_members.append(member)\n",
    "#     texts = [_get_node_text(m, content_bytes) for m in simple_members]\n",
    "#     return ClassWithSimpleMembers(True, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_singles(terms: list[str]) -> list[str]:\n",
    "    ret = []\n",
    "    joined_term = []\n",
    "    for t in terms:\n",
    "        if len(t) == 1:\n",
    "            joined_term.append(t[0])\n",
    "        elif len(t) > 1:\n",
    "            if len(joined_term) > 0:\n",
    "                ret.append(\"\".join(joined_term))\n",
    "                joined_term = []\n",
    "            ret.append(t)\n",
    "    if len(joined_term) > 0:\n",
    "        ret.append(\"\".join(joined_term))\n",
    "    return ret\n",
    "\n",
    "\n",
    "def split_camel(name: str) -> list[str]:\n",
    "    if name.isupper():\n",
    "        return [name.lower()]\n",
    "    indices = [i for i, x in enumerate(name) if x.isupper() or x.isnumeric()]\n",
    "    indices = [0] + indices + [len(name)]\n",
    "    return join_singles([name[a:b].lower() for a, b in it.pairwise(indices)])\n",
    "\n",
    "\n",
    "def split_identifier(name: str) -> list[str]:\n",
    "    by_spaces = name.split(\" \")\n",
    "    by_underscores = it.chain(*(z.split(\"_\") for z in by_spaces))\n",
    "    return list(it.chain(*(split_camel(z) for z in by_underscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text) -> list[str]:\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return [stemmer.stem(i) for i in tokens]\n",
    "\n",
    "\n",
    "def find_documents(content: str) -> list[list[str]]:\n",
    "    content_bytes = content.encode()\n",
    "    captures = _find_captures(content_bytes)\n",
    "    nodes = [c.node for c in captures.values()]\n",
    "    parents = _calculate_parents_dict(nodes)\n",
    "    children = _to_children_dict(parents)\n",
    "    roots = _get_roots(children)\n",
    "    root_classes = [r for r in roots if captures[r.id].kind == _CaptureKind.CLASS]\n",
    "    if len(root_classes) != 1:\n",
    "        return []\n",
    "    members = [m for m in children[root_classes[0]]]\n",
    "    members.sort(key=lambda m: m.byte_range)\n",
    "    docs: list[list[str]] = []\n",
    "    for i, member in enumerate(members):\n",
    "        doc: list[str] = []\n",
    "        capture = captures[member.id]\n",
    "        if not capture.kind.is_function():\n",
    "            continue\n",
    "        for child in children[member]:\n",
    "            if captures[child.id].kind == _CaptureKind.IDENTIFIER:\n",
    "                stemmer = PorterStemmer()\n",
    "                doc += [stemmer.stem(t) for t in split_identifier(child.text.decode())]\n",
    "            if captures[child.id].kind.is_comment():\n",
    "                doc += preprocess(child.text.decode())\n",
    "        if i - 1 >= 0 and captures[members[i - 1].id].kind.is_comment():\n",
    "            doc += preprocess(members[i - 1].text.decode())\n",
    "        docs.append(doc)\n",
    "    return docs\n",
    "\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, *, start, limit, step):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.LsiModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        model_list.append(model)\n",
    "        model = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(model.get_coherence())\n",
    "    return model_list, coherence_values\n",
    "\n",
    "\n",
    "def calc_sim_matrix(docs, *, start=2, limit=10, step=2):\n",
    "    dictionary = corpora.Dictionary(docs)\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "    model_list, coherence_values = compute_coherence_values(dictionary, corpus, docs, start=start, limit=limit, step=step)\n",
    "    lsi = model_list[coherence_values.index(max(coherence_values))]\n",
    "    index = gensim.similarities.MatrixSimilarity(lsi[corpus])\n",
    "    similarity_matrix = np.zeros((len(corpus), len(corpus)))\n",
    "    for i, similarities in enumerate(index):\n",
    "        similarity_matrix[i] = similarities\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "def calc_acsm(sim_mat) -> float:\n",
    "    return np.mean(sim_mat[np.triu_indices(len(sim_mat), k=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"\"\"\n",
    "package depends.matrix.core;\n",
    "\n",
    "\n",
    "public class DependencyDetail {\n",
    "\tprivate LocationInfo from;\n",
    "\tprivate LocationInfo to;\n",
    "\n",
    "\tpublic DependencyDetail(LocationInfo from, LocationInfo to) {\n",
    "    \t// Hello\n",
    "\t\tthis.from = from;\n",
    "\t\tthis.to = to;\n",
    "\t}\n",
    "    \n",
    "\t@Override\n",
    "\tpublic String toString() {\n",
    "\t\treturn from + \"->\" + to;\n",
    "\t}\n",
    "\n",
    "\tpublic LocationInfo getSrc() {\n",
    "\t\t// Hello\n",
    "\t\treturn from;\n",
    "\t}\n",
    "\n",
    "    /*\n",
    "    * This gets the destination. Use it wisely.\n",
    "    */\n",
    "\tpublic LocationInfo getDest() {\n",
    "\t\treturn to;\n",
    "\t}\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['depend', 'detail', 'hello'],\n",
       " ['to', 'string'],\n",
       " ['get', 'src', 'hello'],\n",
       " ['get', 'dest', 'get', 'destin', 'use', 'wise']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = find_documents(example)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 0.00000000e+00, 3.33333313e-01, 7.76540787e-09],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [3.33333313e-01, 0.00000000e+00, 9.99999940e-01, 4.08248276e-01],\n",
       "       [7.76540787e-09, 0.00000000e+00, 4.08248276e-01, 1.00000000e+00]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_mat = calc_sim_matrix(docs, start=2, limit=10, step=2)\n",
    "sim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1235969327914906"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acsm = calc_acsm(sim_mat)\n",
    "acsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True, False, False],\n",
       "       [ True, False,  True,  True]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sim_mat > acsm)[[1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True, False],\n",
       "       [False,  True, False, False],\n",
       "       [ True, False,  True,  True],\n",
       "       [False, False,  True,  True]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_mat > acsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = defaultdict(set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
