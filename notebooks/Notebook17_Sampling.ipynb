{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from typing import Iterator\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from entitybert.selection import prepare_file_ranker_df\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemLookup[T]:\n",
    "    def __init__(self):\n",
    "        self._items: dict[int, list[T]] = defaultdict(list)\n",
    "\n",
    "    def add_item(self, value: int, item: T):\n",
    "        self._items[value].append(item)\n",
    "\n",
    "    def within(self, value_range: range) -> Iterator[T]:\n",
    "        for value in value_range:\n",
    "            yield from self._items[value]\n",
    "\n",
    "\n",
    "class File:\n",
    "    def __init__(self, id: int, lloc: int, entities: int):\n",
    "        self.id = id\n",
    "        self.lloc = lloc\n",
    "        self.entities = entities\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"File(id={self.id}, lloc={self.lloc}, entities={self.entities})\"\n",
    "\n",
    "\n",
    "class FileLookup:\n",
    "    def __init__(self):\n",
    "        self._files: dict[int, File] = dict()\n",
    "        self._by_lloc: ItemLookup[File] = ItemLookup()\n",
    "        self._by_entities: ItemLookup[File] = ItemLookup()\n",
    "\n",
    "    def add_file(self, file: File):\n",
    "        if file.id in self._files:\n",
    "            raise ValueError(\"duplicate file id\")\n",
    "        self._files[file.id] = file\n",
    "        self._by_lloc.add_item(file.lloc, file)\n",
    "        self._by_entities.add_item(file.entities, file)\n",
    "\n",
    "    def rand_file(self) -> File:\n",
    "        return random.choice(list(self._files.values()))\n",
    "\n",
    "    def within(self, lloc_range: range, entities_range: range) -> set[File]:\n",
    "        lloc = self._by_lloc.within(lloc_range)\n",
    "        entities = self._by_entities.within(entities_range)\n",
    "        return set(lloc) & set(entities)\n",
    "\n",
    "\n",
    "class ProjectLookup:\n",
    "    def __init__(self):\n",
    "        self._projects: dict[str, FileLookup] = defaultdict(FileLookup)\n",
    "\n",
    "    def add_file(self, project: str, file: File):\n",
    "        self._projects[project].add_file(file)\n",
    "\n",
    "    def rand_project(self) -> str:\n",
    "        return random.choice(list(self._projects.keys()))\n",
    "\n",
    "    def rand_file(self, project: str) -> File:\n",
    "        return self._projects[project].rand_file()\n",
    "\n",
    "    def rand_file_within_range(\n",
    "        self, project: str, lloc_range: range, entities_range: range\n",
    "    ) -> File | None:\n",
    "        files = self._projects[project].within(lloc_range, entities_range)\n",
    "        if len(files) == 0:\n",
    "            return None\n",
    "        return random.choice(list(files))\n",
    "\n",
    "    def rand_file_pair(\n",
    "        self, lloc_tol: int, entities_tol: int\n",
    "    ) -> tuple[File, File] | None:\n",
    "        a_project = self.rand_project()\n",
    "        b_project = self.rand_project()\n",
    "        a_file = self.rand_file(a_project)\n",
    "        lloc_range = range(max(0, a_file.lloc - lloc_tol), a_file.lloc + lloc_tol + 1)\n",
    "        entities_range = range(\n",
    "            max(0, a_file.entities - entities_tol), a_file.entities + entities_tol + 1\n",
    "        )\n",
    "        b_file = self.rand_file_within_range(b_project, lloc_range, entities_range)\n",
    "        if b_file is None:\n",
    "            return None\n",
    "        if a_file.id == b_file.id:\n",
    "            return None\n",
    "        return (a_file, b_file)\n",
    "\n",
    "    def sample_n_pairs(\n",
    "        self, lloc_tol: int, entities_tol: int, n: int\n",
    "    ) -> list[tuple[File, File]]:\n",
    "        ids: set[int] = set()\n",
    "        pairs: set[tuple[File, File]] = set()\n",
    "        while len(pairs) < n:\n",
    "            pair = self.rand_file_pair(lloc_tol, entities_tol)\n",
    "            if pair is None:\n",
    "                continue\n",
    "            if pair[0].id in ids or pair[1].id in ids:\n",
    "                continue\n",
    "            ids.add(pair[0].id)\n",
    "            ids.add(pair[1].id)\n",
    "            pairs.add(pair)\n",
    "        return list(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_ascii(text: str):\n",
    "    try:\n",
    "        text.encode(\"ascii\")\n",
    "    except UnicodeEncodeError:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"_data/dbs_test.txt\") as f:\n",
    "    db_paths = sorted(line.rstrip() for line in f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for db_path in tqdm(db_paths):\n",
    "    df = prepare_file_ranker_df(db_path)\n",
    "    df.insert(0, \"project\", db_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df = df[[is_ascii(c) for c in df[\"content\"]]]\n",
    "df = df.sort_values([\"project\", \"filename\"])\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.astype({\"loc\": \"int32\", \"lloc\": \"int32\", \"entities\": \"int32\", \"commits\": \"int32\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df: pd.DataFrame, global_quantile: float) -> pd.DataFrame:\n",
    "    columns = [\"lloc\", \"commits\"]\n",
    "    global_thresholds = df[columns].quantile(global_quantile)\n",
    "    return df[(df[columns] >= global_thresholds).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_50p = filter_df(df, 0.5)\n",
    "df_filtered_50p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_75p = filter_df(df, 0.75)\n",
    "df_filtered_75p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered_75p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lloc_tol_raw = df_filtered[\"lloc\"].std() * (1 / 64)\n",
    "print(lloc_tol_raw)\n",
    "lloc_tol = round(lloc_tol_raw)\n",
    "print(lloc_tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_tol_raw = df_filtered[\"entities\"].std() * (1 / 64)\n",
    "print(entities_tol_raw)\n",
    "entities_tol = round(entities_tol_raw)\n",
    "print(entities_tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_lookup = ProjectLookup()\n",
    "\n",
    "for ix, row in df_filtered.iterrows():\n",
    "    lloc = row[\"lloc\"]\n",
    "    entities = row[\"entities\"]\n",
    "    project_lookup.add_file(row[\"project\"], File(int(ix), lloc, entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = project_lookup.sample_n_pairs(entities_tol=entities_tol, lloc_tol=lloc_tol, n=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_rows = []\n",
    "\n",
    "for position, (file_a, file_b) in enumerate(pairs):\n",
    "    row_a = df.loc[file_a.id]\n",
    "    row_b = df.loc[file_b.id]\n",
    "    out_rows.append({\n",
    "        \"position\": position,\n",
    "        \"project_a\": row_a[\"project\"],\n",
    "        \"project_b\": row_b[\"project\"],\n",
    "        \"filename_a\": row_a[\"filename\"],\n",
    "        \"filename_b\": row_b[\"filename\"],\n",
    "        \"content_a\": row_a[\"content\"],\n",
    "        \"content_b\": row_b[\"content\"],\n",
    "    })\n",
    "\n",
    "out_df = pd.DataFrame.from_records(out_rows, index=\"position\")\n",
    "out_df.insert(0, \"sequence\", \"testset-largefiles-75p\")\n",
    "out_df.to_csv(\"testset-largefiles-75p.csv\")\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
