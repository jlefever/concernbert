[global]
seed=42

[io]
models_dir=_models
dataset_train_path=_data/entities_train_nonldl.parquet
dataset_val_path=_data/entities_val_all.parquet
output_model_name=EntityBERT

[training]
base_model_name=huggingface/CodeBERTa-small-v1
use_cosine=0
learning_rate=1e-5
weight_decay=0.01
epochs=2
min_labels=4
max_points_per_label=8

[validation]
checkpoint_steps=10
checkpoint_limit=100
val_files=100
val_batch_size=32
